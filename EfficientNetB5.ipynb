{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:46:50.920551Z","iopub.execute_input":"2022-05-17T12:46:50.921188Z","iopub.status.idle":"2022-05-17T12:47:00.050421Z","shell.execute_reply.started":"2022-05-17T12:46:50.921151Z","shell.execute_reply":"2022-05-17T12:47:00.049468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check data directory\nimport os\nos.listdir(\"../input/face-shape-dataset/FaceShape Dataset\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:47:00.054323Z","iopub.execute_input":"2022-05-17T12:47:00.054581Z","iopub.status.idle":"2022-05-17T12:47:00.065829Z","shell.execute_reply.started":"2022-05-17T12:47:00.054541Z","shell.execute_reply":"2022-05-17T12:47:00.064942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom efficientnet_pytorch import EfficientNet\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:47:00.067435Z","iopub.execute_input":"2022-05-17T12:47:00.068072Z","iopub.status.idle":"2022-05-17T12:47:00.075234Z","shell.execute_reply.started":"2022-05-17T12:47:00.06803Z","shell.execute_reply":"2022-05-17T12:47:00.074519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data split train, val","metadata":{}},{"cell_type":"code","source":"def split_train_val(data_dir, val_size=0.1, random_state=42):\n    train, test = [], []\n    for dset in os.listdir(data_dir):\n        # check is directory\n        subdir = os.path.join(data_dir, dset)\n        if os.path.isdir(subdir):\n            for label in os.listdir(subdir):\n                imgdir = os.path.join(subdir, label)\n                if os.path.isdir(imgdir):\n                    for image_path in os.listdir(imgdir):\n                        if image_path.endswith(\".jpg\"):\n                            sample = {\n                                \"path\": os.path.join(subdir, label, image_path),\n                                \"label\": label\n                            }\n                            if dset == \"training_set\":\n                                train.append(sample)\n                            elif dset == \"testing_set\":\n                                test.append(sample)\n    \n    train = pd.DataFrame(train)\n    test = pd.DataFrame(test)\n    train, val = train_test_split(train, test_size=val_size, random_state=random_state)\n    # save to csv\n#     train_path, val_path, test_path = os.path.join(data_dir, \"train.csv\"), os.path.join(data_dir, \"val.csv\"), os.path.join(data_dir, \"test.csv\")\n#     train.to_csv(train_path, index=False)\n#     val.to_csv(val_path, index=False)\n#     test.to_csv(test_path, index=False)\n    \n    return train, val, test\n\ntrain_df, val_df, test_df = split_train_val(\"../input/face-shape-dataset/FaceShape Dataset\")\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:47:00.077138Z","iopub.execute_input":"2022-05-17T12:47:00.077692Z","iopub.status.idle":"2022-05-17T12:47:00.147688Z","shell.execute_reply.started":"2022-05-17T12:47:00.07759Z","shell.execute_reply":"2022-05-17T12:47:00.147017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize some images and labels","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt  \n\ndef display_examples():\n    \n    \"\"\"\n        Display 25 images from the images and labels\n    \"\"\"\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        img_path = train_df.iloc[i][\"path\"]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        plt.imshow(image, cmap=plt.cm.binary)\n        plt.xlabel(train_df.iloc[i][\"label\"])\n    plt.show()\n\ndisplay_examples()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:48:06.603813Z","iopub.execute_input":"2022-05-17T12:48:06.604067Z","iopub.status.idle":"2022-05-17T12:48:09.743948Z","shell.execute_reply.started":"2022-05-17T12:48:06.604039Z","shell.execute_reply":"2022-05-17T12:48:09.740558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# Dataset\nclass FaceShapeDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform=None, split=\"train\"):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.split = split\n        class_names = ['Heart', 'Oblong', 'Oval', 'Round', 'Square']\n        self.label2idx = {class_name:i for i, class_name in enumerate(class_names)}\n        self.idx2label = {v:k for k,v in self.label2idx.items()}\n    \n    def __len__(self):\n        return len(self.df)\n\n   \n    def __getitem__(self, idx):\n        try:\n            img_path = self.df.loc[idx, \"path\"]\n            img = Image.open(img_path).convert('L')\n            if self.transform:\n                img = self.transform(img)\n            \n            label = self.df.loc[idx, \"label\"]\n            label = self.label2idx[label]\n            return img, torch.tensor(label)\n        except:\n            print(f\"Error load image {img_path}\")\n            idx = 0\n            img_path = self.df.loc[idx, \"path\"]\n            img = Image.open(img_path).convert('L')\n            if self.transform:\n                img = self.transform(img)\n            \n            label = self.df.loc[idx, \"label\"]\n            label = self.label2idx[label]\n            return img, torch.tensor(label)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:53:02.009986Z","iopub.execute_input":"2022-05-17T12:53:02.010243Z","iopub.status.idle":"2022-05-17T12:53:02.020559Z","shell.execute_reply.started":"2022-05-17T12:53:02.010214Z","shell.execute_reply":"2022-05-17T12:53:02.019878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet","metadata":{}},{"cell_type":"code","source":"# Models\nclass EffNet(nn.Module):\n    def __init__(self, num_classes=5):\n        super(EffNet, self).__init__()\n        self.eff = EfficientNet.from_pretrained('efficientnet-b5', num_classes=num_classes, in_channels=1)\n    def forward(self, x):\n        x = self.eff(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:53:03.034293Z","iopub.execute_input":"2022-05-17T12:53:03.03457Z","iopub.status.idle":"2022-05-17T12:53:03.04252Z","shell.execute_reply.started":"2022-05-17T12:53:03.034538Z","shell.execute_reply":"2022-05-17T12:53:03.041683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n    best_accuracy = 0\n    for epoch in range(epochs):\n        model.train()\n        bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training Epoch {}\".format(epoch+1))\n        for batch_idx, (data, target) in bar:\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            bar.set_postfix(loss=loss.item())\n        \n        \n        model.eval()\n        val_loss = 0\n        correct = 0\n        \n        with torch.no_grad():\n            bar = tqdm(enumerate(val_loader), total=len(val_loader), desc=\"Validation Epoch {}\".format(epoch+1))\n            for batch_idx, (data, target) in bar:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                val_loss += F.cross_entropy(output, target, reduction='sum').item()\n                pred = output.argmax(dim=1, keepdim=True)\n                correct += pred.eq(target.view_as(pred)).sum().item()\n        val_loss /= len(val_loader.dataset)\n        val_accuracy = 100. * correct / len(val_loader.dataset)\n        print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n            val_loss, correct, len(val_loader.dataset),\n            val_accuracy))\n        \n        # save best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            torch.save(model.state_dict(), \"./best_model.pth\")\n            print(\"Saved best model\")\n        print(\"Best accuracy: {}\".format(best_accuracy))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:49:02.730838Z","iopub.execute_input":"2022-05-17T12:49:02.731381Z","iopub.status.idle":"2022-05-17T12:49:02.742853Z","shell.execute_reply.started":"2022-05-17T12:49:02.731341Z","shell.execute_reply":"2022-05-17T12:49:02.74175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start training","metadata":{}},{"cell_type":"code","source":"# Configs\nclass args:\n    data_dir=\"../input/face-shape-dataset/FaceShape Dataset\"\n    batch_size=32\n    n_epochs=20\n    learning_rate=0.001\n    debug=False","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:50:18.646966Z","iopub.execute_input":"2022-05-17T12:50:18.647239Z","iopub.status.idle":"2022-05-17T12:50:18.653955Z","shell.execute_reply.started":"2022-05-17T12:50:18.647207Z","shell.execute_reply":"2022-05-17T12:50:18.653139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df, test_df = split_train_val(args.data_dir)\nif args.debug:\n    train_df, val_df = train_df.sample(n=10).reset_index(drop=True), val_df.sample(n=10).reset_index(drop=True)\n\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntrain_loader = torch.utils.data.DataLoader(\n    FaceShapeDataset(train_df, transform=transform, split=\"train\"),\n    batch_size=args.batch_size, shuffle=True\n)\nval_loader = torch.utils.data.DataLoader(\n    FaceShapeDataset(val_df, transform=transform, split=\"val\"),\n    batch_size=args.batch_size, shuffle=False\n)\n\nimport time\nfrom datetime import timedelta\nst = time.time()\nprint(\"-------- Start training --------\")\nmodel = EffNet().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\nmodel = train(model, train_loader, val_loader, criterion, optimizer, epochs=args.n_epochs, device=device)\nprint(\"-------- End training, time taken:\", timedelta(seconds=int(time.time()-st)))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:00:28.60971Z","iopub.execute_input":"2022-05-17T13:00:28.610337Z","iopub.status.idle":"2022-05-17T13:00:37.638107Z","shell.execute_reply.started":"2022-05-17T13:00:28.610302Z","shell.execute_reply":"2022-05-17T13:00:37.637423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on Test set","metadata":{}},{"cell_type":"code","source":"test_ds = FaceShapeDataset(test_df, transform=transform, split=\"test\")\ntest_loader = torch.utils.data.DataLoader(\n    test_ds,\n    batch_size=args.batch_size, shuffle=False\n)\n\nmodel.eval()\ntest_loss = 0\ncorrect = 0\ny_true = []\ny_pred = []\nwith torch.no_grad():\n    for data, target in test_loader:\n        data, target = data.to(device), target.to(device)\n        output = model(data)\n        test_loss += F.cross_entropy(output, target, reduction='sum').item()\n        pred = output.argmax(dim=1, keepdim=True)\n        correct += pred.eq(target.view_as(pred)).sum().item()\n        y_true += target.view(-1).tolist()\n        y_pred += pred.view(-1).tolist()\ntest_loss /= len(test_loader.dataset)\nprint('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n    test_loss, correct, len(test_loader.dataset),\n    100. * correct / len(test_loader.dataset)))\n\ny_true = [test_ds.idx2label[i] for i in y_true]\ny_pred = [test_ds.idx2label[i] for i in y_pred]\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:54:39.461212Z","iopub.execute_input":"2022-05-17T12:54:39.46147Z","iopub.status.idle":"2022-05-17T12:54:57.987403Z","shell.execute_reply.started":"2022-05-17T12:54:39.46144Z","shell.execute_reply":"2022-05-17T12:54:57.98655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\n\nCM = confusion_matrix(y_true, y_pred)\nclass_names = list(test_ds.label2idx.keys())\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T12:57:10.579984Z","iopub.execute_input":"2022-05-17T12:57:10.58023Z","iopub.status.idle":"2022-05-17T12:57:10.87897Z","shell.execute_reply.started":"2022-05-17T12:57:10.580201Z","shell.execute_reply":"2022-05-17T12:57:10.878281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize some predicted results","metadata":{}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nfrom random import randint\n\nlist_idx = [randint(0, len(test_ds)) for i in range(25)]\n\ndef display_examples():\n    \n    \"\"\"\n        Display 25 images from the images and labels\n    \"\"\"\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the test set\", fontsize=16)\n    for i,idx in enumerate(list_idx):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        img_path = test_ds.df.iloc[idx][\"path\"]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        plt.imshow(image, cmap=plt.cm.binary)\n        plt.xlabel(y_true[idx])\n    plt.show()\n\ndisplay_examples()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:07:22.85612Z","iopub.execute_input":"2022-05-17T13:07:22.856373Z","iopub.status.idle":"2022-05-17T13:07:28.489108Z","shell.execute_reply.started":"2022-05-17T13:07:22.856344Z","shell.execute_reply":"2022-05-17T13:07:28.488346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_examples():\n    \n    \"\"\"\n        Display 25 images from the images and labels\n    \"\"\"\n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of predictive images of the test set\", fontsize=16)\n    for i,idx in enumerate(list_idx):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        img_path = test_ds.df.iloc[idx][\"path\"]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        plt.imshow(image, cmap=plt.cm.binary)\n        plt.xlabel(y_pred[idx])\n    plt.show()\n\ndisplay_examples()","metadata":{"execution":{"iopub.status.busy":"2022-05-17T13:08:03.896539Z","iopub.execute_input":"2022-05-17T13:08:03.897243Z","iopub.status.idle":"2022-05-17T13:08:07.334193Z","shell.execute_reply.started":"2022-05-17T13:08:03.8972Z","shell.execute_reply":"2022-05-17T13:08:07.333571Z"},"trusted":true},"execution_count":null,"outputs":[]}]}